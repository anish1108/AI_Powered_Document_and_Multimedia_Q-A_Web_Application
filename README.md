

An AI-powered web application that allows users to upload **PDFs, audio, or video files**, automatically extract or transcribe content, and interact with it through a **chatbot interface**.

The system generates summaries and answers user questions using the uploaded content as context.

---

## ğŸš€ Features

âœ… Upload PDF, Audio, or Video files  
âœ… Automatic speech-to-text transcription (Deepgram API)  
âœ… PDF text extraction  
âœ… AI Chatbot Q&A over uploaded content  
âœ… Auto-generated summaries  
âœ… Timestamp-based answers for media files  
âœ… Media player with jump-to-time functionality  
âœ… Clean React + Tailwind UI  
âœ… Django REST backend

---

## ğŸ—ï¸ Tech Stack

### Backend
- Django 6
- Django REST Framework
- Deepgram (Speech-to-Text)
- Groq API (LLM for Q&A)
- Sumy (Text Summarization)
- Python

### Frontend
- React (Vite)
- Tailwind CSS
- Axios

---





---

## âš™ï¸ Setup Guide

---

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/YOUR_USERNAME/ai-chat-bot.git
cd ai-chat-bot
```

---

## ğŸ§  Backend Setup (Django)

### Create Virtual Environment

```bash
cd backend
python -m venv venv
```

Activate:

**Windows**
```bash
venv\Scripts\activate
```

**Mac/Linux**
```bash
source venv/bin/activate
```

---

### Install Dependencies

```bash
pip install -r requirements.txt
```

---

### Environment Variables

Create a `.env` file inside `backend/`:

```
DEEPGRAM_API_KEY=your_deepgram_key
GROQ_API_KEY=your_groq_key
```

---

### Run Migrations

```bash
python manage.py migrate
```

---

### Start Backend Server

```bash
python manage.py runserver
```

Backend runs at:

```
http://127.0.0.1:8000
```

---

## ğŸ¨ Frontend Setup (React)

Open new terminal:

```bash
cd frontend
npm install
```

Run frontend:

```bash
npm run dev
```

Frontend runs at:

```
http://localhost:5173
```

---

## ğŸ“¡ API Endpoints

---

### Upload File

```
POST /api/user/upload/
```

FormData:
```
file: <pdf | audio | video>
```

Response:
```json
{
  "transcript_id": 1,
  "file_url": "/media/uploads/file.mp3"
}
```

---

### Ask Question

```
POST /api/user/ask/
```

FormData:
```
transcript_id
question
```

Response:
```json
{
  "answer": "Explanation based on uploaded content",
  "start_time": 35.2
}
```

---

### Generate Summary

```
POST /api/user/summary/
```

FormData:
```
transcript_id
```

Response:
```json
{
  "summary": "Short summary of uploaded content..."
}
```

---

## ğŸ§ª Testing the Application

### Step-by-step Test Flow

1. Start backend server
2. Start frontend server
3. Open browser â†’ `localhost:5173`
4. Upload:
   - PDF OR
   - Audio OR
   - Video file
5. Wait for processing
6. Navigate to Chat page
7. Ask questions about content
8. View summary panel
9. Click timestamps to jump media playback

---

## ğŸ§  How It Works

### Processing Pipeline

#### PDF
```
Upload â†’ Text Extraction â†’ Database Storage â†’ Chat Context
```

#### Audio / Video
```
Upload
   â†“
Deepgram Transcription
   â†“
Transcript Saved
   â†“
AI Q&A via Groq
```

---

### Question Answering Flow

```
User Question
      â†“
Fetch Transcript
      â†“
Send Context + Question to LLM
      â†“
Generate Answer
      â†“
Return Timestamp (if media)
```

---

## ğŸ” Security Notes

- API keys stored in `.env`
- `.env` excluded via `.gitignore`
- CSRF disabled only for development APIs

---

## ğŸ§© Future Improvements

- Streaming chat responses
- Semantic search (vector embeddings)
- Multi-file workspace
- User authentication
- Cloud storage support
- Background task queue (Celery)




